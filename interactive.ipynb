{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17002d1e750949349cad6f93f74ad090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import LoftQConfig, LoraConfig, get_peft_model, TaskType\n",
    "import torch\n",
    "\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17fac980ded24291ad98614ba3c0bc80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/51.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6eae7d84ffb426389e0fa7deab8d8b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d930bc42c9874aa8a1c43ac37165a79d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "# model_id = \"distilbert/distilgpt2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "# base_model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_id,\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     device_map=\"auto\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    inference_mode=False,\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules = [\"q_proj\", \"v_proj\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages = [\n",
    "#     {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "#     {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "# ]\n",
    "\n",
    "# input_ids = tokenizer.apply_chat_template(\n",
    "#     messages,\n",
    "#     add_generation_prompt=True,\n",
    "#     return_tensors=\"pt\"\n",
    "# ).to(peft_model.device)\n",
    "\n",
    "# terminators = [\n",
    "#     tokenizer.eos_token_id,\n",
    "#     tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "# ]\n",
    "\n",
    "# print(tokenizer.decode(input_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs = peft_model.generate(\n",
    "#     input_ids,\n",
    "#     max_new_tokens=256,\n",
    "#     eos_token_id=terminators,\n",
    "#     do_sample=True,\n",
    "#     temperature=0.6,\n",
    "#     top_p=0.9,\n",
    "# )\n",
    "# response = outputs[0][input_ids.shape[-1]:]\n",
    "# print(tokenizer.decode(response, skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1522\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"datasets/M1_preference_data_15052024.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ec5a17612f343b08b5781d17082e594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1522 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: the prompt here can be constructed for llama specifically during data processing\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "dpo_dataset_dict = {\n",
    "    \"prompt\": [],\n",
    "    \"chosen\": [],\n",
    "    \"rejected\": [],\n",
    "}\n",
    "\n",
    "# msg = {\"role\": \"system\", \"content\": \"You are an expert professor, teaching a student how to solve a problem. The student expects an accurate and correct answer to the question that has a thorough explanation of how the correct answer is reached.\"}\n",
    "msg = {\"role\": \"system\", \"content\": \"You are an expert professor, teaching a student how to solve a problem by providing a full explanation of the solution.\"}\n",
    "\n",
    "\n",
    "for dp in tqdm(data):\n",
    "    \n",
    "    qn = dp[\"question_complete\"]\n",
    "    \n",
    "    for pref in dp[\"preference\"]:\n",
    "        assert pref[\"overall\"] in [\"A\", \"B\"]\n",
    "        \n",
    "        # dpo_dataset_dict[\"prompt\"].append(qn)\n",
    "        \n",
    "        msg_qn = {\"role\": \"user\", \"content\": qn}\n",
    "        \n",
    "        msg_chosen = {\"role\": \"assistant\", \"content\": pref[pref[\"overall\"]]}\n",
    "        msg_rejected = {\"role\": \"assistant\", \"content\": pref[\"A\" if pref[\"overall\"] == \"B\" else \"B\"]}\n",
    "        \n",
    "        dpo_dataset_dict[\"prompt\"].append([msg, msg_qn])\n",
    "        \n",
    "        # chosen = tokenizer.apply_chat_template(msg + msg_qn + msg_chosen, tokenize=False)\n",
    "        dpo_dataset_dict[\"chosen\"].append([msg_chosen])\n",
    "        \n",
    "        # rejected = tokenizer.apply_chat_template(msg + msg_qn + msg_rejected, tokenize=False)\n",
    "        dpo_dataset_dict[\"rejected\"].append([msg_rejected])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/input_dpo_dataset.json\", \"w\") as f:\n",
    "    json.dump(dpo_dataset_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are an expert professor, teaching a student how to solve a problem by providing a full explanation of the solution.'},\n",
       " {'role': 'user',\n",
       "  'content': 'Question: Select \\\\emph{incorrect} statement. The exhaustive search?\\n\\nOptions:\\nA. can be used to find a secret key of AES.\\nB. is a brute force attack.\\nC. is not applicable against perfectly secure cipher.\\nD. runs in time polynomial in the length of the key.'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpo_dataset_dict[\"prompt\"][17234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1223c0e67c4248938bc52181b2c01eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=64):   0%|          | 0/26738 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e94327ef0749b8be371700687c5da7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/27 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "dpo_ds = Dataset.from_dict(dpo_dataset_dict)\n",
    "\n",
    "\n",
    "def process(row):\n",
    "    row[\"prompt\"] = tokenizer.apply_chat_template(row[\"prompt\"], tokenize=False)\n",
    "    row[\"chosen\"] = tokenizer.apply_chat_template(row[\"chosen\"], tokenize=False)\n",
    "    row[\"rejected\"] = tokenizer.apply_chat_template(row[\"rejected\"], tokenize=False)\n",
    "    return row\n",
    "\n",
    "ds = dpo_ds.map(\n",
    "    process,\n",
    "    num_proc=multiprocessing.cpu_count(),\n",
    "    load_from_cache_file=False,\n",
    ")\n",
    "\n",
    "ds.to_json(\"datasets/dpo_hf_dataset.json\")\n",
    "\n",
    "ds = ds.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9effa7fb595447a7aecf23d4fb3f0dec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'chosen', 'rejected'],\n",
       "    num_rows: 26738\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_loaded = Dataset.from_json(\"datasets/dpo_hf_dataset.json\")\n",
    "ds_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [128000, 128000, 128006, 9125, 128007, 271, 4599, 1595, 13676, 63, 374, 2663, 389, 264, 1796, 11, 279, 1595, 6861, 63, 323, 1595, 23609, 63, 7677, 1629, 304, 59060, 45414, 1471, 15437, 892, 13, 4815, 644, 279, 1162, 1405, 400, 77, 1144, 273, 80, 220, 20, 55976, 279, 6471, 8640, 304, 59060, 45414, 1471, 15437, 892, 2533, 433, 5480, 988, 927, 279, 5540, 315, 279, 1160, 3131, 382, 644, 279, 1162, 1405, 400, 77, 871, 220, 20, 55976, 279, 1160, 374, 6859, 1139, 1403, 5596, 315, 17715, 6273, 1404, 11, 323, 279, 1595, 13676, 63, 734, 374, 53947, 2663, 389, 1855, 4376, 13, 1115, 45473, 1920, 9731, 3156, 279, 1404, 315, 279, 1207, 18035, 9221, 2753, 1109, 477, 6273, 311, 220, 20, 13, 4815, 791, 8149, 315, 279, 51362, 5021, 304, 420, 1162, 649, 387, 30239, 439, 11263, 1473, 12, 2468, 279, 1176, 2237, 315, 51362, 11, 279, 1160, 374, 6859, 1139, 1403, 5596, 627, 12, 2468, 279, 2132, 2237, 11, 1855, 315, 1521, 1403, 5596, 374, 6859, 1139, 1403, 5596, 11, 13239, 304, 264, 2860, 315, 220, 19, 5596, 627, 12, 1115, 45473, 9731, 3156, 279, 1404, 315, 1855, 94993, 374, 2753, 1109, 477, 6273, 311, 220, 20, 382, 55915, 11, 279, 1396, 315, 31919, 41567, 4460, 311, 8108, 279, 1160, 311, 1207, 18035, 315, 1404, 220, 20, 477, 2753, 374, 59060, 848, 62, 17, 1471, 14, 20, 15437, 382, 39, 768, 11, 279, 97354, 14546, 8149, 315, 279, 1595, 13676, 63, 734, 994, 2663, 389, 264, 1796, 374, 59060, 848, 62, 17, 1471, 14, 20, 15437, 11, 1405, 400, 77, 3, 374, 279, 1404, 315, 279, 1796, 13, 128009], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "270\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer(ds_loaded[0][\"chosen\"]))\n",
    "print(len(tokenizer(ds_loaded[0][\"chosen\"])[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are an expert professor, teaching a student how to solve a problem by providing a full explanation of the solution.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nQuestion: Consider the following contains function defined on Iterable (in particular, it accepts both Vector and List).  def contains[A](l: Iterable[A], elem: A): Boolean =   val n = l.size   if n <= 5 then     for i <- l do       if i == elem then         return true     false   else     val (p0, p1) = parallel(       contains(l.take(n / 2), elem),       contains(l.drop(n / 2), elem)     )   p0 || p1 Let $n$$n$ be the size of l. Assume that drop and take run in $\\\\Theta(1)$ on Vector and $\\\\Theta(n)$ on List. What is the asymptotic depth of contains if it is called on a List?<|eot_id|>',\n",
       " 'chosen': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nWhen `contains` is called on a List, the `drop` and `take` operations run in $\\\\Theta(n)$ time. \\n\\nIn the case where $n \\\\leq 5$, the loop runs in $\\\\Theta(n)$ time since it iterates over the elements of the list once.\\n\\nIn the case where $n > 5$, the list is split into two parts of roughly equal size, and the `contains` function is recursively called on each half. This splitting process continues until the size of the sublists becomes less than or equal to 5. \\n\\nThe depth of the recursion tree in this case can be analyzed as follows:\\n\\n- At the first level of recursion, the list is split into two parts.\\n- At the second level, each of these two parts is split into two parts, resulting in a total of 4 parts.\\n- This splitting continues until the size of each sublist is less than or equal to 5.\\n\\nTherefore, the number of recursive splits needed to reduce the list to sublists of size 5 or less is $\\\\log_2(n/5)$.\\n\\nHence, the asymptotic depth of the `contains` function when called on a List is $\\\\log_2(n/5)$, where $n$ is the size of the List.<|eot_id|>',\n",
       " 'rejected': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nThe asymptotic depth of the contains function when called on a List is $\\\\log_2(n)$, where $n$ is the size of the List. This is because the function recursively splits the List in half each time it is called, leading to a binary tree structure with a depth of $\\\\log_2(n)$.<|eot_id|>'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_loaded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b274d2fbbee54457be48568afccba2b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/26738 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6f3d7dec1d241c7ab3e4849c66fd8ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/26738 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0689845ba7e4371b5732a03ae2d699b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/26738 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_prompt_tokens = ds_loaded.map(lambda examples: tokenizer(examples['prompt']), batched=True)\n",
    "ds_chosen_tokens = ds_loaded.map(lambda examples: tokenizer(examples['chosen']), batched=True)\n",
    "ds_rejected_tokens = ds_loaded.map(lambda examples: tokenizer(examples['rejected']), batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'chosen', 'rejected', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 26738\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_prompt_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1244\n",
      "2157\n",
      "2069\n"
     ]
    }
   ],
   "source": [
    "prompt_lens = [len(x['input_ids']) for x in ds_prompt_tokens]\n",
    "print(max(prompt_lens))\n",
    "\n",
    "chosen_lens = [len(x['input_ids']) for x in ds_chosen_tokens]\n",
    "print(max(chosen_lens))\n",
    "\n",
    "rejected_lens = [len(x['input_ids']) for x in ds_rejected_tokens]\n",
    "print(max(rejected_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "627"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "sum(np.array(rejected_lens) + np.array(prompt_lens) > 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist([prompt_lens, chosen_lens, rejected_lens], 50, histtype=\"bar\")\n",
    "plt.legend([\"Prompt\", \"Chosen\", \"Rejected\"])\n",
    "plt.xlim([0, 1000])\n",
    "plt.savefig(\"data_dist.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_prompt_length, max_length, loss_type. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in DPOTrainer, please use the DPOConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TrainingArguments' object has no attribute 'model_init_kwargs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m ds_loaded \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mfrom_json(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets/dpo_hf_dataset.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m ds_loaded \u001b[38;5;241m=\u001b[39m ds_loaded\u001b[38;5;241m.\u001b[39mtrain_test_split(test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mDPOTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;66;43;03m# peft_model,\u001b[39;49;00m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# ref_model,# ref_peft_model,\u001b[39;49;00m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds_loaded\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds_loaded\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpeft_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlora_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_prompt_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrobust\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# precompute_ref_log_probs=True,\u001b[39;49;00m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# callbacks=[RichProgressCallback] if TRL_USE_RICH else None,\u001b[39;49;00m\n\u001b[1;32m     41\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/project-code-2024/venv/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:101\u001b[0m, in \u001b[0;36m_deprecate_arguments.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m         message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m custom_message\n\u001b[1;32m    100\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/project-code-2024/venv/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:174\u001b[0m, in \u001b[0;36mDPOTrainer.__init__\u001b[0;34m(self, model, ref_model, beta, label_smoothing, loss_type, args, data_collator, label_pad_token_id, padding_value, truncation_mode, train_dataset, eval_dataset, tokenizer, model_init, callbacks, optimizers, preprocess_logits_for_metrics, max_length, max_prompt_length, max_target_length, peft_config, is_encoder_decoder, disable_dropout, generate_during_eval, compute_metrics, precompute_ref_log_probs, dataset_num_proc, model_init_kwargs, ref_model_init_kwargs, model_adapter_name, ref_adapter_name, reference_free, force_use_ref_model)\u001b[0m\n\u001b[1;32m    169\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou passed `model_init_kwargs` to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    171\u001b[0m     )\n\u001b[1;32m    172\u001b[0m     args\u001b[38;5;241m.\u001b[39mmodel_init_kwargs \u001b[38;5;241m=\u001b[39m model_init_kwargs\n\u001b[0;32m--> 174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_init_kwargs\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    175\u001b[0m     model_init_kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TrainingArguments' object has no attribute 'model_init_kwargs'"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "from datasets import Dataset\n",
    "from trl import DPOTrainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=1,\n",
    "    learning_rate=5e-5,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    num_train_epochs=1,\n",
    "    gradient_accumulation_steps=1,\n",
    "    logging_steps=10,\n",
    "    eval_steps=500,\n",
    "    optim=\"adamw_torch_fused\",\n",
    "    warmup_ratio=0.1,\n",
    "    max_grad_norm=0.3,\n",
    "    output_dir=\"logs\",\n",
    "    remove_unused_columns=False,\n",
    "    push_to_hub=False,\n",
    "    report_to=\"tensorboard\",\n",
    ")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "ds_loaded = Dataset.from_json(\"datasets/dpo_hf_dataset.json\")\n",
    "ds_loaded = ds_loaded.train_test_split(test_size=0.2)\n",
    "\n",
    "trainer = DPOTrainer(\n",
    "    base_model,# peft_model,\n",
    "    # ref_model,# ref_peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds_loaded[\"train\"],\n",
    "    eval_dataset=ds_loaded[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    peft_config=lora_config,\n",
    "    max_prompt_length=512,\n",
    "    max_length=1024,\n",
    "    beta=0.1,\n",
    "    loss_type=\"robust\",\n",
    "    # precompute_ref_log_probs=True,\n",
    "    # callbacks=[RichProgressCallback] if TRL_USE_RICH else None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d4bf67ed2e04def832b4ecc96dd0018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train dataset reference log probs:   0%|          | 0/21390 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/project-code-2024/venv/lib/python3.10/site-packages/transformers/trainer.py:1859\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1857\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1858\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1860\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1862\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1864\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/project-code-2024/venv/lib/python3.10/site-packages/transformers/trainer.py:1888\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1886\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrently training with a batch size of: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1887\u001b[0m \u001b[38;5;66;03m# Data loader and number of training steps\u001b[39;00m\n\u001b[0;32m-> 1888\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_train_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_fsdp_xla_v2_enabled:\n\u001b[1;32m   1890\u001b[0m     train_dataloader \u001b[38;5;241m=\u001b[39m tpu_spmd_dataloader(train_dataloader)\n",
      "File \u001b[0;32m~/project-code-2024/venv/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:477\u001b[0m, in \u001b[0;36mget_train_dataloader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    475\u001b[0m     args\u001b[38;5;241m.\u001b[39mbeta \u001b[38;5;241m=\u001b[39m beta\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mbeta\n\u001b[0;32m--> 477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_smoothing \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mlabel_smoothing\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_type \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mloss_type\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stored_metrics \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28;01mlambda\u001b[39;00m: defaultdict(\u001b[38;5;28mlist\u001b[39m))\n",
      "File \u001b[0;32m~/project-code-2024/venv/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:771\u001b[0m, in \u001b[0;36mcompute_reference_log_probs\u001b[0;34m(self, padded_batch)\u001b[0m\n\u001b[1;32m    768\u001b[0m rejected_prompt_len_input_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(rejected_tokens[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_input_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    769\u001b[0m prompt_len_input_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(chosen_prompt_len_input_ids, rejected_prompt_len_input_ids)\n\u001b[0;32m--> 771\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m prompt_tokens\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    772\u001b[0m     prompt_tokens[k] \u001b[38;5;241m=\u001b[39m v[:prompt_len_input_ids]\n\u001b[1;32m    774\u001b[0m \u001b[38;5;66;03m# Make sure prompts only have one different token at most an\u001b[39;00m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;66;03m# and length only differs by 1 at most\u001b[39;00m\n",
      "File \u001b[0;32m~/project-code-2024/venv/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:985\u001b[0m, in \u001b[0;36mconcatenated_forward\u001b[0;34m(self, model, batch)\u001b[0m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdpo_loss\u001b[39m(\n\u001b[1;32m    978\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    979\u001b[0m     policy_chosen_logps: torch\u001b[38;5;241m.\u001b[39mFloatTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    982\u001b[0m     reference_rejected_logps: torch\u001b[38;5;241m.\u001b[39mFloatTensor,\n\u001b[1;32m    983\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mFloatTensor, torch\u001b[38;5;241m.\u001b[39mFloatTensor, torch\u001b[38;5;241m.\u001b[39mFloatTensor]:\n\u001b[1;32m    984\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the DPO loss for a batch of policy and reference model log probabilities.\u001b[39;00m\n\u001b[0;32m--> 985\u001b[0m \n\u001b[1;32m    986\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;124;03m        policy_chosen_logps: Log probabilities of the policy model for the chosen responses. Shape: (batch_size,)\u001b[39;00m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;124;03m        policy_rejected_logps: Log probabilities of the policy model for the rejected responses. Shape: (batch_size,)\u001b[39;00m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;124;03m        reference_chosen_logps: Log probabilities of the reference model for the chosen responses. Shape: (batch_size,)\u001b[39;00m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;124;03m        reference_rejected_logps: Log probabilities of the reference model for the rejected responses. Shape: (batch_size,)\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \n\u001b[1;32m    992\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[38;5;124;03m        A tuple of three tensors: (losses, chosen_rewards, rejected_rewards).\u001b[39;00m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;124;03m        The losses tensor contains the DPO loss for each example in the batch.\u001b[39;00m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;124;03m        The chosen_rewards and rejected_rewards tensors contain the rewards for the chosen and rejected responses, respectively.\u001b[39;00m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    997\u001b[0m     pi_logratios \u001b[38;5;241m=\u001b[39m policy_chosen_logps \u001b[38;5;241m-\u001b[39m policy_rejected_logps\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreference_free:\n",
      "File \u001b[0;32m~/project-code-2024/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/project-code-2024/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/project-code-2024/venv/lib/python3.10/site-packages/peft/peft_model.py:1430\u001b[0m, in \u001b[0;36mPeftModelForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_peft_forward_hooks(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1429\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_peft_forward_args}\n\u001b[0;32m-> 1430\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1431\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1432\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1433\u001b[0m \u001b[43m            \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1434\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1435\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1436\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1437\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1438\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1439\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1441\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m _get_batch_size(input_ids, inputs_embeds)\n\u001b[1;32m   1442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1443\u001b[0m     \u001b[38;5;66;03m# concat prompt attention mask\u001b[39;00m\n",
      "File \u001b[0;32m~/project-code-2024/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/project-code-2024/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/project-code-2024/venv/lib/python3.10/site-packages/peft/tuners/tuners_utils.py:179\u001b[0m, in \u001b[0;36mBaseTuner.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any):\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/project-code-2024/venv/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:1211\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1208\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1211\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1212\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1224\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/project-code-2024/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/project-code-2024/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/project-code-2024/venv/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:1018\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1007\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1008\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1009\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1015\u001b[0m         cache_position,\n\u001b[1;32m   1016\u001b[0m     )\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1018\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1028\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/project-code-2024/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/project-code-2024/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/project-code-2024/venv/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:755\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    753\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n\u001b[1;32m    754\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m--> 755\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost_attention_layernorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    756\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(hidden_states)\n\u001b[1;32m    757\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/project-code-2024/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/project-code-2024/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/project-code-2024/venv/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:89\u001b[0m, in \u001b[0;36mLlamaRMSNorm.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m     87\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     88\u001b[0m variance \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 89\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m*\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrsqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariance\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariance_epsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m*\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mto(input_dtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
