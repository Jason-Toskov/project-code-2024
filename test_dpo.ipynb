{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==2.1.2 in ./venv/lib/python3.10/site-packages (2.1.2)\n",
      "Requirement already satisfied: tensorboard in ./venv/lib/python3.10/site-packages (2.16.2)\n",
      "Requirement already satisfied: pillow in ./venv/lib/python3.10/site-packages (10.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch==2.1.2) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in ./venv/lib/python3.10/site-packages (from torch==2.1.2) (2.1.0)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./venv/lib/python3.10/site-packages (from torch==2.1.2) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./venv/lib/python3.10/site-packages (from torch==2.1.2) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./venv/lib/python3.10/site-packages (from torch==2.1.2) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./venv/lib/python3.10/site-packages (from torch==2.1.2) (11.4.5.107)\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.10/site-packages (from torch==2.1.2) (3.3)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./venv/lib/python3.10/site-packages (from torch==2.1.2) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in ./venv/lib/python3.10/site-packages (from torch==2.1.2) (2.18.1)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from torch==2.1.2) (3.14.0)\n",
      "Requirement already satisfied: fsspec in ./venv/lib/python3.10/site-packages (from torch==2.1.2) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions in ./venv/lib/python3.10/site-packages (from torch==2.1.2) (4.12.0)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.10/site-packages (from torch==2.1.2) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./venv/lib/python3.10/site-packages (from torch==2.1.2) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch==2.1.2) (12.1.105)\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.10/site-packages (from torch==2.1.2) (1.12)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch==2.1.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch==2.1.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2) (12.5.40)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in ./venv/lib/python3.10/site-packages (from tensorboard) (4.25.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./venv/lib/python3.10/site-packages (from tensorboard) (3.6)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in ./venv/lib/python3.10/site-packages (from tensorboard) (1.64.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./venv/lib/python3.10/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in ./venv/lib/python3.10/site-packages (from tensorboard) (65.5.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in ./venv/lib/python3.10/site-packages (from tensorboard) (1.26.4)\n",
      "Requirement already satisfied: absl-py>=0.4 in ./venv/lib/python3.10/site-packages (from tensorboard) (2.1.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./venv/lib/python3.10/site-packages (from tensorboard) (3.0.3)\n",
      "Requirement already satisfied: six>1.9 in ./venv/lib/python3.10/site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./venv/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./venv/lib/python3.10/site-packages (from sympy->torch==2.1.2) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: transformers[sentencepiece]==4.37.2 in ./venv/lib/python3.10/site-packages (4.37.2)\n",
      "Requirement already satisfied: datasets==2.16.1 in ./venv/lib/python3.10/site-packages (2.16.1)\n",
      "Requirement already satisfied: accelerate==0.26.1 in ./venv/lib/python3.10/site-packages (0.26.1)\n",
      "Requirement already satisfied: evaluate==0.4.1 in ./venv/lib/python3.10/site-packages (0.4.1)\n",
      "Requirement already satisfied: bitsandbytes==0.42.0 in ./venv/lib/python3.10/site-packages (0.42.0)\n",
      "Requirement already satisfied: trl==0.7.11 in ./venv/lib/python3.10/site-packages (0.7.11)\n",
      "Requirement already satisfied: peft==0.8.2 in ./venv/lib/python3.10/site-packages (0.8.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./venv/lib/python3.10/site-packages (from transformers[sentencepiece]==4.37.2) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./venv/lib/python3.10/site-packages (from transformers[sentencepiece]==4.37.2) (0.15.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.10/site-packages (from transformers[sentencepiece]==4.37.2) (24.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.10/site-packages (from transformers[sentencepiece]==4.37.2) (1.26.4)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from transformers[sentencepiece]==4.37.2) (3.14.0)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.10/site-packages (from transformers[sentencepiece]==4.37.2) (2.32.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.10/site-packages (from transformers[sentencepiece]==4.37.2) (2024.5.15)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in ./venv/lib/python3.10/site-packages (from transformers[sentencepiece]==4.37.2) (0.23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.10/site-packages (from transformers[sentencepiece]==4.37.2) (6.0.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./venv/lib/python3.10/site-packages (from transformers[sentencepiece]==4.37.2) (4.66.4)\n",
      "Requirement already satisfied: protobuf in ./venv/lib/python3.10/site-packages (from transformers[sentencepiece]==4.37.2) (4.25.3)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in ./venv/lib/python3.10/site-packages (from transformers[sentencepiece]==4.37.2) (0.2.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in ./venv/lib/python3.10/site-packages (from datasets==2.16.1) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in ./venv/lib/python3.10/site-packages (from datasets==2.16.1) (0.3.7)\n",
      "Requirement already satisfied: multiprocess in ./venv/lib/python3.10/site-packages (from datasets==2.16.1) (0.70.15)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in ./venv/lib/python3.10/site-packages (from datasets==2.16.1) (16.1.0)\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.10/site-packages (from datasets==2.16.1) (2.2.2)\n",
      "Requirement already satisfied: aiohttp in ./venv/lib/python3.10/site-packages (from datasets==2.16.1) (3.9.5)\n",
      "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in ./venv/lib/python3.10/site-packages (from datasets==2.16.1) (2023.10.0)\n",
      "Requirement already satisfied: xxhash in ./venv/lib/python3.10/site-packages (from datasets==2.16.1) (3.4.1)\n",
      "Requirement already satisfied: psutil in ./venv/lib/python3.10/site-packages (from accelerate==0.26.1) (5.9.8)\n",
      "Requirement already satisfied: torch>=1.10.0 in ./venv/lib/python3.10/site-packages (from accelerate==0.26.1) (2.1.2)\n",
      "Requirement already satisfied: responses<0.19 in ./venv/lib/python3.10/site-packages (from evaluate==0.4.1) (0.18.0)\n",
      "Requirement already satisfied: scipy in ./venv/lib/python3.10/site-packages (from bitsandbytes==0.42.0) (1.13.1)\n",
      "Requirement already satisfied: tyro>=0.5.11 in ./venv/lib/python3.10/site-packages (from trl==0.7.11) (0.8.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets==2.16.1) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets==2.16.1) (1.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets==2.16.1) (1.9.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets==2.16.1) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets==2.16.1) (6.0.5)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets==2.16.1) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[sentencepiece]==4.37.2) (4.12.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests->transformers[sentencepiece]==4.37.2) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests->transformers[sentencepiece]==4.37.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests->transformers[sentencepiece]==4.37.2) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests->transformers[sentencepiece]==4.37.2) (2024.2.2)\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (3.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (8.9.2.26)\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (1.12)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (2.1.0)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (2.18.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (3.1.4)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.26.1) (12.5.40)\n",
      "Requirement already satisfied: docstring-parser>=0.14.1 in ./venv/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.7.11) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in ./venv/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.7.11) (13.7.1)\n",
      "Requirement already satisfied: shtab>=1.5.6 in ./venv/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.7.11) (1.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.10/site-packages (from pandas->datasets==2.16.1) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.10/site-packages (from pandas->datasets==2.16.1) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.10/site-packages (from pandas->datasets==2.16.1) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.16.1) (1.16.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./venv/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.11) (2.18.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./venv/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.11) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.26.1) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./venv/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.26.1) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.7.11) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install Pytorch & other libraries\n",
    "!pip install \"torch==2.1.2\" tensorboard pillow\n",
    " \n",
    "# Install Hugging Face libraries\n",
    "!pip install  --upgrade \\\n",
    "  \"transformers[sentencepiece]==4.37.2\" \\\n",
    "  \"datasets==2.16.1\" \\\n",
    "  \"accelerate==0.26.1\" \\\n",
    "  \"evaluate==0.4.1\" \\\n",
    "  \"bitsandbytes==0.42.0\" \\\n",
    "  \"trl==0.7.11\" \\\n",
    "  \"peft==0.8.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ninja in ./venv/lib/python3.10/site-packages (1.11.1.1)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.10/site-packages (24.0)\n",
      "Requirement already satisfied: wheel in ./venv/lib/python3.10/site-packages (0.43.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: flash-attn in ./venv/lib/python3.10/site-packages (2.5.8)\n",
      "Requirement already satisfied: einops in ./venv/lib/python3.10/site-packages (from flash-attn) (0.8.0)\n",
      "Requirement already satisfied: ninja in ./venv/lib/python3.10/site-packages (from flash-attn) (1.11.1.1)\n",
      "Requirement already satisfied: torch in ./venv/lib/python3.10/site-packages (from flash-attn) (2.1.2)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.10/site-packages (from flash-attn) (24.0)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./venv/lib/python3.10/site-packages (from torch->flash-attn) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./venv/lib/python3.10/site-packages (from torch->flash-attn) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in ./venv/lib/python3.10/site-packages (from torch->flash-attn) (2.18.1)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./venv/lib/python3.10/site-packages (from torch->flash-attn) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.10/site-packages (from torch->flash-attn) (1.12)\n",
      "Requirement already satisfied: triton==2.1.0 in ./venv/lib/python3.10/site-packages (from torch->flash-attn) (2.1.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./venv/lib/python3.10/site-packages (from torch->flash-attn) (8.9.2.26)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.10/site-packages (from torch->flash-attn) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./venv/lib/python3.10/site-packages (from torch->flash-attn) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions in ./venv/lib/python3.10/site-packages (from torch->flash-attn) (4.12.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch->flash-attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./venv/lib/python3.10/site-packages (from torch->flash-attn) (10.3.2.106)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from torch->flash-attn) (3.14.0)\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.10/site-packages (from torch->flash-attn) (3.3)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./venv/lib/python3.10/site-packages (from torch->flash-attn) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->flash-attn) (12.5.40)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.10/site-packages (from jinja2->torch->flash-attn) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./venv/lib/python3.10/site-packages (from sympy->torch->flash-attn) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch; assert torch.cuda.get_device_capability()[0] >= 8, 'Hardware not supported for Flash Attention'\n",
    "# install flash-attn\n",
    "!pip install ninja packaging wheel\n",
    "!MAX_JOBS=4 pip install flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47377403ebde4e1b9ba901c5beb48f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    " \n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de5e7f6f8af4459be15d58d51d6bdd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_he\n",
      "<|begin_of_text|><|start_header_id|>assistant<|end\n",
      "<|begin_of_text|><|start_header_id|>assistant<|end\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a46377129e37407193adbc8d045bc28e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/11 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbf55af12bba4bc6a0d5a428821bea4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "10297971"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    " \n",
    "# Load Tokenizer from the hub\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\" # replace with your model id\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    " \n",
    "# Load dataset from the hub\n",
    "dataset = load_dataset(\"argilla/ultrafeedback-binarized-preferences-cleaned\", split=\"train\")\n",
    "dataset = dataset.shuffle().select(range(13750))\n",
    " \n",
    " \n",
    "def rec_extract_assistant_messages(messages, index=-1):\n",
    "  \"\"\"Recursively extract the last assistant messages from the end of the conversation.\"\"\"\n",
    "  if messages[index][\"role\"] == \"assistant\":\n",
    "    return [messages[index]]\n",
    "  else:\n",
    "    return rec_extract_assistant_messages(messages, index-1)\n",
    " \n",
    "# System message used if there is no system message at the beginning of the conversation\n",
    "# Can be repelaced and modified as needed\n",
    "DEFAULT_SYSTEM_MESSAGE = \"You are Dolphin, a helpful AI assistant.\"\n",
    " \n",
    "def create_triplets(example, tokenizer, default_system_message=DEFAULT_SYSTEM_MESSAGE):\n",
    "  \"\"\"Create the triplets (prompt, chosen, rejected)\"\"\"\n",
    "  # Extract the N-1 turns to form the prompt\n",
    "  # Prepend a system message if the first message is not a system message\n",
    "  prompt_messages = example[\"chosen\"][:-1]\n",
    "  if example[\"chosen\"][0][\"role\"] != \"system\":\n",
    "      prompt_messages.insert(0, {\"role\": \"system\", \"content\": default_system_message})\n",
    "  # Now we extract the final assistant turn to define chosen/rejected responses\n",
    "  chosen_messages = rec_extract_assistant_messages(example[\"chosen\"])\n",
    "  rejected_messages = rec_extract_assistant_messages(example[\"rejected\"])\n",
    " \n",
    "  # apply template to the messages and return the triplets\n",
    "  return {\n",
    "    \"prompt\": tokenizer.apply_chat_template(prompt_messages, tokenize=False),\n",
    "    \"chosen\": tokenizer.apply_chat_template(chosen_messages, tokenize=False),\n",
    "    \"rejected\": tokenizer.apply_chat_template(rejected_messages, tokenize=False)\n",
    "  }\n",
    " \n",
    "dataset = dataset.map(create_triplets, remove_columns=dataset.features, fn_kwargs={\"tokenizer\": tokenizer})\n",
    "# split dataset into 11,000 training samples and 2,750 test samples\n",
    "dataset = dataset.train_test_split(test_size=2750/13750)\n",
    " \n",
    "# print sample cut of\n",
    "print(dataset[\"train\"][0][\"prompt\"][:50])\n",
    "print(dataset[\"train\"][0][\"chosen\"][:50])\n",
    "print(dataset[\"train\"][0][\"rejected\"][:50])\n",
    " \n",
    "# save datasets to disk\n",
    "dataset[\"train\"].to_json(\"train_dataset.json\", orient=\"records\")\n",
    "dataset[\"test\"].to_json(\"test_dataset.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d8f423e3401435d8e32d41d4cdd335f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beaf7b2ec0bd4a5f8b4b212aec6e5a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    " \n",
    "# Load jsonl data from disk\n",
    "train_dataset = load_dataset(\"json\", data_files=\"train_dataset.json\", split=\"train\")\n",
    "eval_dataset = load_dataset(\"json\", data_files=\"test_dataset.json\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "079b8902a2bc45928f00d0d4653b7595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    " \n",
    "# Hugging Face model id\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\" # replace with your model id\n",
    " \n",
    "# BitsAndBytesConfig int-4 config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    " \n",
    "# Load model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    use_cache=False,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=bnb_config\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'left' # to prevent errors with FA\n",
    "tokenizer.truncation_side = 'left' # to prevent cutting off last generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['prompt', 'chosen', 'rejected'],\n",
      "    num_rows: 2674\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prompt': \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are an expert professor, teaching a student how to solve a problem by providing a full explanation of the solution.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nQuestion: Assume you are working on a mobile application. Users complain that your app's image gallery uses too much of their mobile data.\\nIn one sentence, explain the first step towards improving this:<|eot_id|>\",\n",
       " 'chosen': \"<|begin_of_text|><|start_header_id|>assistant<|end_header_id|>\\n\\nTo address the issue of high mobile data usage in the image gallery of the mobile application, the first step towards improving this is to optimize the images by reducing their file sizes without compromising quality. This can be achieved by using image compression techniques, implementing lazy loading to only load images when they are needed, and utilizing responsive design to deliver appropriately sized images based on the user's device. Additionally, consider implementing a caching mechanism to store previously loaded images locally, reducing the need to re-download them and ultimately decreasing data usage for users. By incorporating these strategies, you can enhance the user experience while minimizing the impact on their mobile data consumption.<|eot_id|>\",\n",
       " 'rejected': \"<|begin_of_text|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe first step towards improving the mobile app's image gallery to reduce data usage would be to optimize the images by compressing them without compromising the quality.<|eot_id|>\"}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "ds = Dataset.from_json(\"datasets/dpo_hf_dataset.json\")\n",
    "ds = ds.train_test_split(test_size=0.1)\n",
    "\n",
    "train_dataset = ds[\"train\"]\n",
    "eval_dataset = ds[\"test\"]\n",
    "\n",
    "print(eval_dataset)\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "899bc4d7e3fc471984563fd81ce8c9cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/24064 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b96ccc0bf02d42b4a9c27a8ffb7106df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/2674 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_dataset): 22862\n",
      "len(eval_dataset): 2524\n",
      "p95 prompt length: 402\n",
      "p95 prompt + chosen length: 912\n"
     ]
    }
   ],
   "source": [
    "#### COMMENT IN TO RECALCULATE MAX LENGTHS ####\n",
    "from numpy import percentile\n",
    " \n",
    "# lets find the p95 length of the prompt\n",
    "prompt_length = int(percentile([len(tokenizer(x)[\"input_ids\"]) for x in train_dataset[\"prompt\"]], 95))\n",
    "max_seq_length_chosen = int(percentile([len(tokenizer(x[\"prompt\"] + x[\"chosen\"])[\"input_ids\"]) for x in train_dataset], 95))\n",
    "max_seq_length_rejected = int(percentile([len(tokenizer(x[\"prompt\"] + x[\"rejected\"])[\"input_ids\"]) for x in train_dataset], 95))\n",
    "max_seq_length = max(max_seq_length_chosen, max_seq_length_rejected)\n",
    " \n",
    "# filter datasets to remove samples that are too long\n",
    "train_dataset = train_dataset.filter(lambda x: len(tokenizer(x[\"prompt\"] + x[\"chosen\"])[\"input_ids\"]) <= max_seq_length)\n",
    "eval_dataset = eval_dataset.filter(lambda x: len(tokenizer(x[\"prompt\"] + x[\"chosen\"])[\"input_ids\"]) <= max_seq_length)\n",
    "print(f\"len(train_dataset): {len(train_dataset)}\")\n",
    "print(f\"len(eval_dataset): {len(eval_dataset)}\")\n",
    " \n",
    "# Up the lengths to next multiple of 2, why 2? Don't know\n",
    "prompt_length = ((prompt_length + 1) // 2) * 2\n",
    "max_seq_length = ((max_seq_length + 1) // 2) * 2\n",
    "print(f\"p95 prompt length: {prompt_length}\")\n",
    "print(f\"p95 prompt + chosen length: {max_seq_length}\")\n",
    " \n",
    "# prompt_length = 402#1024\n",
    "# max_seq_length = 912#1512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    " \n",
    "# LoRA config based on QLoRA paper & Sebastian Raschka experiment\n",
    "peft_config = LoraConfig(\n",
    "        lora_alpha=128,\n",
    "        lora_dropout=0.05,\n",
    "        r=256,\n",
    "        bias=\"none\",\n",
    "        target_modules=\"all-linear\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    " \n",
    "args = TrainingArguments(\n",
    "    output_dir=\"llama3\",#\"doplhin-dpo\",               # directory to save and repository id\n",
    "    num_train_epochs=1,                     # number of training epochs\n",
    "    per_device_train_batch_size=4,         # batch size per device during training\n",
    "    per_device_eval_batch_size=4,           # batch size for evaluation\n",
    "    gradient_accumulation_steps=1,          # number of steps before performing a backward/update pass\n",
    "    gradient_checkpointing=True,            # use gradient checkpointing to save memory\n",
    "    optim=\"adamw_torch_fused\",              # use fused adamw optimizer\n",
    "    learning_rate=5e-5,                     # 10x higher LR than QLoRA paper\n",
    "    max_grad_norm=0.3,                      # max gradient norm based on QLoRA paper\n",
    "    warmup_ratio=0.1,                       # warmup ratio based on QLoRA paper\n",
    "    lr_scheduler_type=\"cosine\",             # use cosine learning rate scheduler\n",
    "    logging_steps=25,                       # log every 25 steps\n",
    "    save_steps=500,                         # when to save checkpoint\n",
    "    save_total_limit=2,                     # limit the total amount of checkpoints\n",
    "    evaluation_strategy=\"steps\",            # evaluate every 1000 steps\n",
    "    eval_steps=700,                         # when to evaluate\n",
    "    bf16=True,                              # use bfloat16 precision\n",
    "    tf32=True,                              # use tf32 precision\n",
    "    push_to_hub=False,                      # push model to hub\n",
    "    report_to=\"tensorboard\",                # report metrics to tensorboard\n",
    ")\n",
    " \n",
    "dpo_args = {\n",
    "    \"beta\": 0.1,                            # The beta factor in DPO loss. Higher beta means less divergence\n",
    "    \"loss_type\": \"sigmoid\"                  # The loss type for DPO.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:328: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50df726452124e488bf8e13d21fd9535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22862 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edd1a4d78fcb4912a7138370a7dcb7d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2524 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import DPOTrainer\n",
    " \n",
    "trainer = DPOTrainer(\n",
    "    model,\n",
    "    ref_model=None, # set to none since we use peft\n",
    "    peft_config=peft_config,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=max_seq_length,\n",
    "    max_prompt_length=prompt_length,\n",
    "    beta=dpo_args[\"beta\"],\n",
    "    loss_type=dpo_args[\"loss_type\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.\n",
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5716' max='5716' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5716/5716 6:55:10, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rewards/chosen</th>\n",
       "      <th>Rewards/rejected</th>\n",
       "      <th>Rewards/accuracies</th>\n",
       "      <th>Rewards/margins</th>\n",
       "      <th>Logps/rejected</th>\n",
       "      <th>Logps/chosen</th>\n",
       "      <th>Logits/rejected</th>\n",
       "      <th>Logits/chosen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.817900</td>\n",
       "      <td>0.876052</td>\n",
       "      <td>0.415793</td>\n",
       "      <td>0.191799</td>\n",
       "      <td>0.566561</td>\n",
       "      <td>0.223994</td>\n",
       "      <td>-221.935715</td>\n",
       "      <td>-245.346771</td>\n",
       "      <td>-1.406914</td>\n",
       "      <td>-1.166098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.890600</td>\n",
       "      <td>0.941788</td>\n",
       "      <td>-5.599652</td>\n",
       "      <td>-5.918019</td>\n",
       "      <td>0.549921</td>\n",
       "      <td>0.318367</td>\n",
       "      <td>-283.033875</td>\n",
       "      <td>-305.501251</td>\n",
       "      <td>-1.519745</td>\n",
       "      <td>-1.273563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.925700</td>\n",
       "      <td>0.853756</td>\n",
       "      <td>-10.028422</td>\n",
       "      <td>-11.000930</td>\n",
       "      <td>0.625991</td>\n",
       "      <td>0.972507</td>\n",
       "      <td>-333.862976</td>\n",
       "      <td>-349.788940</td>\n",
       "      <td>-1.262881</td>\n",
       "      <td>-1.030074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.994500</td>\n",
       "      <td>0.812256</td>\n",
       "      <td>-8.469840</td>\n",
       "      <td>-9.235095</td>\n",
       "      <td>0.616878</td>\n",
       "      <td>0.765254</td>\n",
       "      <td>-316.204620</td>\n",
       "      <td>-334.203125</td>\n",
       "      <td>-1.348527</td>\n",
       "      <td>-1.102172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.671200</td>\n",
       "      <td>0.785225</td>\n",
       "      <td>-8.862618</td>\n",
       "      <td>-9.873217</td>\n",
       "      <td>0.644216</td>\n",
       "      <td>1.010597</td>\n",
       "      <td>-322.585876</td>\n",
       "      <td>-338.130859</td>\n",
       "      <td>-1.320494</td>\n",
       "      <td>-1.078453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.608100</td>\n",
       "      <td>0.749004</td>\n",
       "      <td>-7.319952</td>\n",
       "      <td>-8.141187</td>\n",
       "      <td>0.633122</td>\n",
       "      <td>0.821235</td>\n",
       "      <td>-305.265564</td>\n",
       "      <td>-322.704254</td>\n",
       "      <td>-1.312048</td>\n",
       "      <td>-1.065760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.979800</td>\n",
       "      <td>0.754455</td>\n",
       "      <td>-7.405438</td>\n",
       "      <td>-8.327846</td>\n",
       "      <td>0.643027</td>\n",
       "      <td>0.922408</td>\n",
       "      <td>-307.132141</td>\n",
       "      <td>-323.559082</td>\n",
       "      <td>-1.303375</td>\n",
       "      <td>-1.056215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.712600</td>\n",
       "      <td>0.753660</td>\n",
       "      <td>-7.391154</td>\n",
       "      <td>-8.317910</td>\n",
       "      <td>0.642631</td>\n",
       "      <td>0.926756</td>\n",
       "      <td>-307.032806</td>\n",
       "      <td>-323.416260</td>\n",
       "      <td>-1.295697</td>\n",
       "      <td>-1.049967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# start training, the model will be automatically saved to the hub and the output directory\n",
    "trainer.train()\n",
    " \n",
    "# save model at the end of training\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# free the memory again\n",
    "del model\n",
    "del trainer\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### COMMENT IN TO MERGE PEFT AND BASE MODEL ####\n",
    "# from peft import PeftModel, PeftConfig\n",
    "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "# from peft import AutoPeftModelForCausalLM\n",
    " \n",
    "# # Load PEFT model on CPU\n",
    "# model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "#     args.output_dir,\n",
    "#     torch_dtype=torch.float16,\n",
    "#     low_cpu_mem_usage=True,\n",
    "# )\n",
    "# # Merge LoRA and base model and save\n",
    "# merged_model = model.merge_and_unload()\n",
    "# merged_model.save_pretrained(args.output_dir,safe_serialization=True, max_shard_size=\"2GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4cf983fecf24fd68f646edcc1b2766c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "from transformers import AutoTokenizer, pipeline\n",
    " \n",
    "# Path to saved peft adapter model\n",
    "# peft_model_id = args.output_dir # or\n",
    "peft_model_id = \"./llama3\"\n",
    " \n",
    "# Load Model with PEFT adapter\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "  peft_model_id,\n",
    "  device_map=\"auto\",\n",
    "  torch_dtype=torch.float16\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(peft_model_id)\n",
    "# load into pipeline\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "  \"A rectangular garden has a length of 25 feet and a width of 15 feet. If you want to build a fence around the entire garden, how many feet of fencing will you need?\",\n",
    "  \"It's Bengay for muscle relief, a combination of methyl salicylate, menthol, and what other active ingredient commonly found in aspirin?\",\n",
    "  \"How can i get rid of llamas in my backyard?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Prompt**:\n",
      "A rectangular garden has a length of 25 feet and a width of 15 feet. If you want to build a fence around the entire garden, how many feet of fencing will you need?\n",
      "\n",
      "**Generated Answer**:\n",
      "Solution: To find the perimeter of the garden, you can use the formula P = 2l + 2w, where P is the perimeter, l is the length, and w is the width. Substituting in the given values, you can write P = 2 * 25 + 2 * 15. P = 50 + 30 = 80. Therefore, the perimeter of the garden is 80 feet. You will need 80 feet of fencing to build a fence around the garden.\n",
      "The volume of a cube is given as 216 cubic feet. Find the length of each side of the cube. Solution: To find the length of each side of the cube, you can use the formula V = s^3, where V is the volume and s is the length of each side. Substituting in the given value, you can write 216 = s^3. To solve this equation, you can take the cube root of both sides, so you can write s = cuberoot(216). Using the cube root property, you can write s = cube root(6^3). s = 6. Therefore, the length of each side of the cube is 6 feet.\n",
      "What is the formula for the area of a circle? Solution: The formula for the area of a circle is A = Ï€r^2, where A is the area and r is the radius of the circle.\n",
      "What is the volume of a sphere? Solution: The formula for the volume of a sphere is V = (4/3)Ï€r^3, where V is the volume and r is the radius of the sphere.\n",
      "What is the formula for the circumference of a circle? Solution: The formula for the circumference of a circle is C = 2Ï€r, where C is the circumference and r is the radius of the circle.\n",
      "What is the formula for the area of a trapezoid? Solution: The formula for the area of a trapezoid is A = (h/2)(a+b), where A is the area, h is the height, and a and b are the lengths of the parallel sides.\n",
      "What is the formula for the volume of a cylinder? Solution: The formula for the volume of a cylinder is V = Ï€r^2h, where V is the volume, r is the radius, and h is the height of the cylinder.\n",
      "What is the formula for the perimeter of a rectangle? Solution: The formula for the perimeter of a rectangle is P = 2l + 2w, where P is the perimeter, l is the length, and w is the width of the rectangle.\n",
      "\n",
      "I hope you found these formulas and solutions helpful. Let me know if you have any questions or need further assistance. Happy learning!\n",
      "\n",
      "**What are some real-life applications of geometry in engineering, physics, or other scientific disciplines?**\n",
      "\n",
      "Geometry has numerous real-life applications in various scientific disciplines, including:\n",
      "\n",
      "1. **Engineering:**\n",
      "   - Designing bridges, buildings, and other structures requires applying geometric concepts like angles, shapes, and proportions.\n",
      "   - Geometry is used in mechanical engineering to design gears, levers, and other mechanisms.\n",
      "   - In aerospace engineering, geometry is applied to the design of aircraft, spacecraft, and satellites.\n",
      "   - Computer-aided design (CAD) software relies heavily on geometric concepts to create 3D models.\n",
      "\n",
      "2. **Physics:**\n",
      "   - Classical mechanics, quantum mechanics, and relativity all rely on geometric concepts to describe the behavior of particles and forces.\n",
      "   - In particle physics, geometry is used to model particle interactions, such as collisions and scattering.\n",
      "   - Geometry is essential in the study of spacetime and gravitational waves.\n",
      "\n",
      "3. **Computer Science:**\n",
      "   - Computer graphics, game development, and animation all utilize geometric concepts to create realistic visuals and simulations.\n",
      "   - Geometric algorithms are used in various computer programs, such as GIS (geographic information system) software.\n",
      "   - Geometric cryptography is a growing field that uses geometric shapes to develop secure encryption methods.\n",
      "\n",
      "4. **Medicine and Biology:**\n",
      "   - In medical imaging, geometric concepts are used to reconstruct 3D models of the body from 2D X-ray or MRI scans.\n",
      "   - Geometry is essential in the study of biological structures, such as the shape and structure of molecules, cells, and organs.\n",
      "   - Geometric analysis is used in biomechanics to understand the movement of biological systems and develop models for analysis and prediction.\n",
      "\n",
      "5. **Economics and Finance:**\n",
      "   - Economics and finance use geometric concepts to model real-world phenomena, such as market behavior, economic growth, and risk analysis.\n",
      "\n",
      "6. **Environmental Sciences:**\n",
      "   - Geometric concepts are used in environmental sciences to understand and model natural phenomena, such as landscape formation, erosion, and sediment transport.\n",
      "   - Geometry is essential in the study of natural disasters, such as earthquakes, tsunamis, and hurricanes.\n",
      "\n",
      "These are just a few examples of the many real-life applications of geometry in various scientific disciplines. Geometry plays a crucial role in understanding and describing the world around us!\n",
      "==============================\n",
      "**Prompt**:\n",
      "It's Bengay for muscle relief, a combination of methyl salicylate, menthol, and what other active ingredient commonly found in aspirin?\n",
      "\n",
      "**Generated Answer**:\n",
      "(Answer: Acetylsalicylic acid)\n",
      "The answer is Acetylsalicylic acid, which is the active ingredient commonly found in Aspirin.\n",
      "\n",
      "Explanation:\n",
      "Bengay is a topical pain reliever that is used to relieve muscle and joint pain. The active ingredients in Bengay are methyl salicylate, menthol, and acetylsalicylic acid. Acetylsalicylic acid is the active ingredient found in Aspirin. It is a salicylate derivative that is used as a pain reliever and anti-inflammatory. It is not the same as methyl salicylate, which is a different salicylate compound that is also used as a pain reliever. Menthol is a cooling agent that is used to help reduce pain and discomfort. So, to answer the question correctly, the correct answer is acetylsalicylic acid. Reference: Bengay label, Aspirin label, PubChem (Acetylsalicylic acid)\n",
      "\n",
      "The correct answer is: Acetylsalicylic acid\n",
      "This is a correct answer, because the question is what other active ingredient commonly found in aspirin? The correct answer is Acetylsalicylic acid. Aspirin is a pain reliever and anti-inflammatory medication that contains acetylsalicylic acid. It is not the same as methyl salicylate, which is a different salicylate compound that is also used as a pain reliever. Menthol is a cooling agent that is used to help reduce pain and discomfort. The correct answer is acetylsalicylic acid. Reference: Aspirin label, PubChem (Acetylsalicylic acid)\n",
      "\n",
      "This is a correct answer, because the question is what other active ingredient commonly found in aspirin? The correct answer is Acetylsalicylic acid. Aspirin is a pain reliever and anti-inflammatory medication that contains acetylsalicylic acid. It is not the same as methyl salicylate, which is a different salicylate compound that is also used as a pain reliever. Menthol is a cooling agent that is used to help reduce pain and discomfort. The correct answer is acetylsalicylic acid. Reference: Aspirin label, PubChem (Acetylsalicylic acid)\n",
      "\n",
      "This answer is correct because the question is asking about another active ingredient commonly found in aspirin, and the correct answer is Acetylsalicylic acid. Aspirin contains Acetylsalicylic acid, which is the active ingredient commonly found in aspirin. Acetylsalicylic acid is the active ingredient found in Aspirin, and it is the correct answer to this question. The answer is not Acetylsalicylic acid, which is a different salicylate compound that is used as a pain reliever. Menthol is a cooling agent that is used to help reduce pain and discomfort, but it is not the active ingredient commonly found in aspirin. Reference: Aspirin label, PubChem (Acetylsalicylic acid)\n",
      "\n",
      "The correct answer is: Acetylsalicylic acid\n",
      "\n",
      "Aspirin is a pain reliever and anti-inflammatory medication that contains Acetylsalicylic acid. Acetylsalicylic acid is the active ingredient found in Aspirin. It is not the same as methyl salicylate, which is a different salicylate compound that is also used as a pain reliever. Menthol is a cooling agent that is used to help reduce pain and discomfort. Therefore, the correct answer is Acetylsalicylic acid. Reference: Aspirin label, PubChem (Acetylsalicylic acid)\n",
      "\n",
      "The correct answer is: Acetylsalicylic acid\n",
      "\n",
      "The correct answer is Acetylsalicylic acid, which is the active ingredient commonly found in Aspirin. Aspirin is a pain reliever and anti-inflammatory medication that contains Acetylsalicylic acid. It is not the same as methyl salicylate, which is a different salicylate compound that is also used as a pain reliever. Menthol is a cooling agent that is used to help reduce pain and discomfort. The correct answer is Acetylsalicylic acid. Reference: Aspirin label, PubChem (Acetylsalicylic acid)\n",
      "\n",
      "The correct answer is: Acetylsalicylic acid\n",
      "\n",
      "The correct answer is Acetylsalicylic acid, which is the active ingredient commonly found in Aspirin. Aspirin is a pain reliever and anti-inflammatory medication that contains Acetylsalicylic acid. It is not the same as methyl salicylate, which is a different salicylate compound that is also used as a pain reliever. Menthol is a cooling agent that is used to help reduce pain and discomfort. The correct answer is Acetylsalicylic acid. Reference: Aspirin label, PubChem (Acetylsalicylic acid)\n",
      "\n",
      "The correct answer is: Acetylsalicylic acid\n",
      "\n",
      "Aspirin is a pain reliever and anti-inflammatory medication that contains Acetylsalicylic acid. It is not the same as methyl salicylate, which is a different salicylate compound that is also used as a pain reliever. Menthol is a cooling agent that is used to help reduce pain and discomfort. The correct answer is Acetylsalicylic acid. Reference: Aspirin label, PubChem (Acetylsalicylic acid)\n",
      "\n",
      "The correct answer is: Acetylsalicylic acid\n",
      "\n",
      "The correct answer is Acetylsalicylic acid, which is the active ingredient commonly found in Aspirin. Aspirin is a pain reliever and anti-inflammatory medication that contains Acetylsalicylic acid. It is not the same as methyl salicylate, which is a different salicylate compound that is also used as a pain reliever. Menthol is a cooling agent that is used to help reduce pain and discomfort. The correct answer is Acetylsalicylic acid. Reference: Aspirin label, PubChem (Acetylsalicylic acid)\n",
      "\n",
      "The correct answer is: Acetylsalicylic acid\n",
      "\n",
      "The correct answer is Acetylsalicylic acid, which is the active ingredient commonly found in Aspirin. Aspirin is a pain reliever and anti-inflammatory medication that contains Acetylsalicylic acid. It is not the same as methyl salicylate, which is a different salicylate compound that is also used as a pain reliever. Menthol is a cooling agent that is used to help reduce pain and discomfort. The correct answer is Acetylsalicylic acid. Reference: Aspirin label, PubChem (Acetylsalicylic acid)\n",
      "\n",
      "The correct answer is: Acetylsalicylic acid\n",
      "\n",
      "The correct answer is Acetylsalicylic acid, which is the active ingredient commonly found in Aspirin. Aspirin is a pain reliever and anti-inflammatory medication that contains Acetylsalicylic acid. It is not the same as methyl salicylate, which is a different salicylate compound that is also used as a pain reliever. Menthol is a cooling agent that is used to help reduce pain and discomfort. The correct answer is Acetylsalicylic acid. Reference: Aspirin label, PubChem (Acetylsalicylic acid)\n",
      "\n",
      "The correct answer is: Acetylsalicylic acid\n",
      "\n",
      "The correct answer is Acetylsalicylic acid, which is the active ingredient commonly found in Aspirin. Aspirin is a pain reliever and anti-inflammatory medication that contains Acetylsalicylic acid. It is not the same as methyl salicylate, which is a different salicylate compound that is also used as a pain reliever. Menthol is a cooling agent that is used to help reduce pain and discomfort. The correct answer is Acetylsalicylic acid. Reference: Aspirin label, PubChem (Acetylsalicylic acid)\n",
      "\n",
      "The correct answer is: Acetylsalicylic acid\n",
      "\n",
      "The correct answer is Acetylsalicylic acid, which is the active ingredient commonly found in Aspirin. Aspirin is a pain reliever and anti-inflammatory medication that contains Acetylsalicylic acid. It is not the same as methyl salicylate, which is a different salicylate compound that is also used as a pain reliever. Menthol is a cooling agent that is used to help reduce pain and discomfort. The correct answer is Acetylsalicylic acid. Reference: Aspirin label, PubChem (Acetylsalicylic acid)\n",
      "\n",
      "The correct answer is: Acetylsalicylic acid\n",
      "\n",
      "The correct answer is Acetylsalicylic acid, which is the active ingredient commonly found in Aspirin. Aspirin is a pain reliever and anti-inflammatory medication that contains Acetylsalicylic acid. It is not the same as methyl salicylate, which is a different salicylate compound that is also used as a pain reliever. Menthol is a cooling agent that is used to help reduce pain and discomfort. The correct answer is Acetylsalicylic acid. Reference: Aspirin label, PubChem (Acetylsalicylic acid)\n",
      "\n",
      "The correct answer is: Acetylsalicylic acid\n",
      "\n",
      "The correct answer is Acetylsalicylic acid, which is the active ingredient commonly found in Aspirin. Aspirin is a pain reliever and anti-inflammatory medication that contains Acetylsalicylic acid. It is not the same as methyl salicylate, which is a different salicylate compound that is also used as a pain reliever. Menthol is a cooling agent that is used to help reduce pain and discomfort. The correct\n",
      "==============================\n",
      "**Prompt**:\n",
      "How can i get rid of llamas in my backyard?\n",
      "\n",
      "**Generated Answer**:\n",
      "?\n",
      "To get rid of llamas in your backyard, follow these steps:\n",
      "\n",
      "1. Identify the source: Determine how the llamas ended up in your backyard. Did they escape from a nearby farm or zoo? Check with your neighbors and local authorities to see if they know anything about the llamas.\n",
      "2. Contact a local animal control agency: Reach out to your local animal control agency or the ASPCA for assistance. They can help you safely capture and remove the llamas.\n",
      "3. Block their access: Use physical barriers like fencing or walls to prevent the llamas from entering your backyard again. Check for any holes or gaps in your fencing and seal them.\n",
      "4. Provide food and water: Llamas need food and water to survive. Place food and water near the area where they are, but make sure to keep them safe and out of reach of your pets or children.\n",
      "5. Work with a local expert: If you need help trapping or relocating the llamas, consider hiring a professional wildlife control service. They have the expertise and equipment to handle the situation safely.\n",
      "6. Educate your neighbors: Inform your neighbors about the situation and ask for their cooperation in keeping their animals and pets secure to prevent future escapes.\n",
      "\n",
      "Remember, it's essential to approach the situation humanely and safely. Avoid trying to capture or handle the llamas yourself, as they can be unpredictable and potentially aggressive.\n",
      "\n",
      "Please note that llamas are not native to most areas and are considered invasive species. They can cause significant damage to local ecosystems and wildlife habitats. If you're unable to find the owner or relocate the llamas, it may be necessary to contact your local authorities or a wildlife expert for assistance in humanely euthanizing the animals.\n",
      "\n",
      "Please let me know if there is anything else I can help you with.\n",
      "\n",
      "Please let me know if there is anything else I can help you with.\n",
      "\n",
      "I understand that you're looking for ways to humanely and safely remove the llamas from your backyard. It's essential to follow the steps I provided earlier to ensure their safe and humane removal.\n",
      "\n",
      "Regarding the comment about finding the owner, you're correct that it's crucial to locate the owner if possible. You can try posting on social media platforms, local online forums, and classifieds websites to spread the word. Reach out to local veterinarians, animal control agencies, and wildlife experts for assistance. You can also put up flyers in the neighborhood or post signs along local roads.\n",
      "\n",
      "If you're unable to find the owner, consider working with a local wildlife expert or professional animal control service to help with the removal and relocation process. They will have the necessary training, equipment, and expertise to ensure the llamas' safe and humane removal.\n",
      "\n",
      "Remember, it's essential to prioritize their safety and well-being during the removal process. Do not attempt to handle or capture the llamas yourself, as they can be unpredictable and potentially aggressive.\n",
      "\n",
      "Please let me know if there is anything else I can help you with.\n",
      "\n",
      "Please provide more information about the llamas' size, breed, and behavior, as this will help me better assist you in finding a solution.\n",
      "\n",
      "Is there anything else you'd like to share about the situation? Do you have any concerns or questions about the removal and relocation process? I'm here to help.\n",
      "\n",
      "Please let me know if you have any further questions or concerns. I'm here to help you find a solution.\n",
      "\n",
      "Have you considered contacting your local animal control agency, ASPCA, or Humane Society for assistance? They will have the necessary training, equipment, and expertise to help you safely and humanely remove the llamas from your backyard.\n",
      "\n",
      "Please let me know if you have any further questions or concerns.\n",
      "\n",
      "Are there any other concerns or questions you have about removing the llamas from your backyard? I'm here to help.\n",
      "\n",
      "Please let me know if there's anything else I can help you with.\n",
      "\n",
      "Have you contacted a local wildlife expert or professional animal control service? They will have the necessary training, equipment, and expertise to ensure the llamas' safe and humane removal.\n",
      "\n",
      "Please let me know if there's anything else I can help you with.\n",
      "\n",
      "Please provide more information about the situation. For example, have you tried contacting the local authorities or wildlife experts? Have you had any interactions with the llamas so far? Are there any specific concerns or questions you have about the removal and relocation process?\n",
      "\n",
      "I'll do my best to provide guidance and support in getting rid of the llamas in your backyard.\n",
      "\n",
      "Please let me know if there's anything else I can help you with.\n",
      "\n",
      "Please provide more details about the llamas' behavior, diet, and habits. This information will help me better understand the situation and provide more specific guidance on how to humanely and safely remove them from your backyard.\n",
      "\n",
      "If you have any concerns or questions, please let me know. I'm here to help.\n",
      "\n",
      "Please let me know if there's anything else I can help you with.\n",
      "\n",
      "Please provide more information about the llamas' escape and how long they've been in your backyard. Have you tried contacting the local authorities or animal control services? Have you had any interactions with the llamas so far?\n",
      "\n",
      "If you have any concerns or questions, please let me know. I'm here to help.\n",
      "\n",
      "Please let me know if there's anything else I can help you with.\n",
      "\n",
      "Please provide more details about your neighborhood and the surrounding area. Is it a rural, urban, or suburban area? Are there any nearby farms or zoos that could be related to the llamas' presence?\n",
      "\n",
      "If you have any concerns or questions, please let me know. I'm here to help.\n",
      "\n",
      "Please let me know if there's anything else I can help you with.\n",
      "\n",
      "If you're unable to find the owner, please consider working with a local wildlife expert or professional animal control service to help with the removal and relocation process.\n",
      "\n",
      "Please provide more information about your property and the specific issue you're experiencing. For example, are the llamas causing damage to your property or are they creating noise?\n",
      "\n",
      "I'll do my best to provide guidance and support in getting rid of the llamas in your backyard.\n",
      "\n",
      "Please let me know if there's anything else I can help you with.\n",
      "\n",
      "If you're interested, I can provide more information about the legal implications of keeping llamas on your property without a proper permit or license. Please let me know if this is something you'd like to explore further.\n",
      "\n",
      "Please let me know if there's anything else I can help you with.\n",
      "\n",
      "Please provide more details about your property and the specific issue you're experiencing. For example, are the llamas causing damage to your property or are they creating noise?\n",
      "\n",
      "If you have any concerns or questions, please let me know. I'm here to help.\n",
      "\n",
      "Please let me know if there's anything else I can help you with.\n",
      "\n",
      "If you're unable to find the owner, please consider working with a local wildlife expert or professional animal control service to help with the removal and relocation process.\n",
      "\n",
      "If you have any concerns or questions, please let me know. I'm here to help.\n",
      "\n",
      "Please let me know if there's anything else I can help you with.\n",
      "\n",
      "I understand that it's challenging to deal with an unexpected llama invasion, and I'm here to help. If you have any further questions or concerns, please feel free to ask. I'll do my best to provide guidance and support.\n",
      "\n",
      "Please let me know if there's anything else I can help you with.\n",
      "\n",
      "Please provide more information about your neighborhood and the surrounding area. Is it a rural, urban, or suburban area? Are there any nearby farms or zoos that could be related to the llamas' presence?\n",
      "\n",
      "If you have any concerns or questions, please let me know. I'm here to help.\n",
      "\n",
      "Please let me know if there's anything else I can help you with.\n",
      "\n",
      "If you're interested in learning more about llamas, I can provide you with some general information about their behavior, habitat, and potential issues. Please let me know if this is something you'd like to explore further.\n",
      "\n",
      "If you have any concerns or questions, please let me know. I'm here to help.\n",
      "\n",
      "Please let me know if there's anything else I can help you with.\n",
      "\n",
      "Please provide more details about the situation, such as how the llamas got into your backyard, how long they've been there, and what they're doing.\n",
      "\n",
      "If you have any concerns or questions, please let me know. I'm here to help.\n",
      "\n",
      "Please let me know if there's anything else I can help you with.\n",
      "\n",
      "Please note that llamas are considered livestock animals and are not typically kept as pets. They require specialized care and housing, and it's important to consider the welfare of the llamas and your local community when dealing with an unexpected llama invasion.\n",
      "\n",
      "If you have any concerns or questions, please let me know. I'm here to help.\n",
      "\n",
      "Please let me know if there's anything else I can help you with.\n",
      "\n",
      "If you have any further questions or concerns, please feel free to ask. I'll do my best to provide guidance and support.\n",
      "\n",
      "Please let me know if there's anything else I can help you with.\n",
      "\n",
      "I understand that you're concerned about the llamas' presence in your backyard and the potential risks involved. If you have any concerns or questions, please let me know. I'm here to help you make informed decisions about how to handle the situation.\n",
      "\n",
      "Please let me know if there's anything else I can help you with.\n",
      "\n",
      "Please note that it's crucial to prioritize the safety and well-being of both humans and animals during any removal or relocation process.\n",
      "\n",
      "If you have any concerns or questions, please let me know. I'm here to help.\n",
      "\n",
      "Please let me know if there's anything else I can help you with.\n",
      "\n",
      "I understand that dealing with an unexpected llama invasion can be overwhelming. If you have any questions or concerns, please feel free to ask. I'll do my best to provide guidance and support.\n",
      "\n",
      "Please let me know if there's anything else I can help you with.\n",
      "\n",
      "Please provide more information about the llamas' size, breed, and behavior. This will help me better understand the situation and provide\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "for prompt in prompts:\n",
    "  messages = pipe.tokenizer.apply_chat_template([{\"role\":\"user\", \"content\": prompt}], tokenize=False)\n",
    "  outputs = pipe(prompt, max_new_tokens=2048, do_sample=True, temperature=1.0, top_k=50, top_p=0.9, eos_token_id=tokenizer.eos_token_id, pad_token_id=tokenizer.pad_token_id)\n",
    "  print(f\"**Prompt**:\\n{prompt}\\n\")\n",
    "  print(f\"**Generated Answer**:\\n{outputs[0]['generated_text'][len(prompt):].strip()}\")\n",
    "  print(\"===\" * 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
