{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import logging\n",
    "\n",
    "from utils import read_jsonl, write_json\n",
    "from evaluator import DPOModelEvaluator, repository_check\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(\"mnlp-2024-auto-evaluator\")\n",
    "\n",
    "# Basic repository check to ensure the submission is correct\n",
    "repository_check()\n",
    "\n",
    "# Load the main configuration file\n",
    "main_config = {}\n",
    "with open(\"main_config.yaml\") as f:\n",
    "    try:\n",
    "        main_config = yaml.safe_load(f)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading main_config.yaml: {e}! Please check the file format.\")\n",
    "\n",
    "# Load the task type to identify the model class\n",
    "task_type = main_config.get(\"task_type\", \"causal_lm\")\n",
    "\n",
    "# Load the evaluation methods and the required paths\n",
    "eval_method = main_config.get(\"eval_method\", [\"mcqa\"])\n",
    "policy_model_path = main_config[\"policy_model_path\"]\n",
    "reference_model_path = main_config[\"reference_model_path\"]\n",
    "test_data_path = main_config[\"test_data_path\"]\n",
    "\n",
    "# Load the test data\n",
    "test_data = read_jsonl(test_data_path)\n",
    "\n",
    "# Load the model arguments\n",
    "dpo_model_args = main_config.get(\"dpo_model_args\", {})\n",
    "rag_model_args = main_config.get(\"rag_model_args\", {})\n",
    "quantized_model_args = main_config.get(\"quantized_model_args\", {})\n",
    "\n",
    "# Initialize the metrics dictionary\n",
    "metrics = {\n",
    "    \"team_name\": main_config.get(\"team_name\", \"Team Name\"),\n",
    "    \"task_type\": task_type,\n",
    "}\n",
    "\n",
    "# Ensure that the evaluation methods are not conflicting\n",
    "assert not (\"reward\" in eval_method and \"mcqa\" in eval_method), \"You cannot evaluate both reward and mcqa at the same time!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "428"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "test_dataloader = DataLoader(test_data[:4], batch_size=4)\n",
    "evaluator = DPOModelEvaluator(\n",
    "    task_type=task_type,\n",
    "    policy_model_path=policy_model_path,\n",
    "    reference_model_path=reference_model_path,\n",
    "    dpo_model_args=dpo_model_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "2024-05-28 09:46:00,142 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf56df210f66479e829ff670f32b6e02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-28 09:46:25,863 - INFO - Trained peft adapter loaded\n",
      "2024-05-28 09:46:25,865 - WARNING - A <class 'peft.peft_model.PeftModelForCausalLM'> model is loaded from './llama3/', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n",
      "2024-05-28 09:46:25,865 - WARNING - A <class 'peft.peft_model.PeftModelForCausalLM'> model is loaded from './llama3/', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      " 25%|██▌       | 1/4 [00:19<00:59, 19.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C']\n",
      "True answer: C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:50<00:51, 25.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D', 'D', 'D', 'D', 'B', 'D', 'D']\n",
      "True answer: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [01:31<00:32, 32.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B', 'B', 'B', 'C', 'B', 'B', 'C', 'C']\n",
      "True answer: D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:55<00:00, 28.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D', 'D', 'D', 'D', 'D', 'D', 'C', 'C', 'D']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "policy_acc= evaluator.scoring_mcqa(test_dataloader)\n",
    "eval_method.remove(\"mcqa\")\n",
    "metrics[\"policy_acc\"] = policy_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toskov/project-code-2024/llama3/venv2/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3910b4db8e9047e79364fe4c2ff2db10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-28 12:04:57,973 - INFO - Trained peft adapter loaded\n",
      "2024-05-28 12:04:57,975 - WARNING - A <class 'peft.peft_model.PeftModelForCausalLM'> model is loaded from './llama3/', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n",
      "2024-05-28 12:04:57,976 - WARNING - A <class 'peft.peft_model.PeftModelForCausalLM'> model is loaded from './llama3/', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/home/toskov/project-code-2024/llama3/venv2/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:332: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# policy_model = evaluator.model_class.from_pretrained(policy_model_path, **evaluator.dpo_model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toskov/project-code-2024/llama3/venv2/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5380e14c2c1348729fc748d88e2c3afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-28 12:56:24,077 - INFO - Trained peft adapter loaded\n",
      "2024-05-28 12:56:24,079 - WARNING - A <class 'peft.peft_model.PeftModelForCausalLM'> model is loaded from './llama3/', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n",
      "2024-05-28 12:56:24,085 - WARNING - A <class 'peft.peft_model.PeftModelForCausalLM'> model is loaded from './llama3/', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/home/toskov/project-code-2024/llama3/venv2/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:332: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[{'role': 'system', 'content': 'You are an expert professor, teaching a student how to solve a problem by providing a full explanation of the solution.'}, {'role': 'user', 'content': \"Explain what's base rate fallacy and list five specific examples of how politicians use it for campaigns.\"}]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "evaluator.compute_reference_logprobs(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/toskov/project-code-2024/evaluator.py\u001b[0m(211)\u001b[0;36mcompute_reference_logprobs\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    209 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    210 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 211 \u001b[0;31m            \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"chosen_logps\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prompt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"chosen_logps\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    212 \u001b[0;31m            \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rejected_logps\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prompt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rejected_logps\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    213 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    " \n",
    "args = TrainingArguments(\n",
    "    output_dir=\"llama3_new\",#\"doplhin-dpo\",               # directory to save and repository id\n",
    "    num_train_epochs=1,                     # number of training epochs\n",
    "    per_device_train_batch_size=1,         # batch size per device during training\n",
    "    per_device_eval_batch_size=1,           # batch size for evaluation\n",
    "    gradient_accumulation_steps=1,          # number of steps before performing a backward/update pass\n",
    "    gradient_checkpointing=True,            # use gradient checkpointing to save memory\n",
    "    optim=\"adamw_torch_fused\",              # use fused adamw optimizer\n",
    "    learning_rate=5e-5,                     # 10x higher LR than QLoRA paper\n",
    "    max_grad_norm=0.3,                      # max gradient norm based on QLoRA paper\n",
    "    warmup_ratio=0.1,                       # warmup ratio based on QLoRA paper\n",
    "    lr_scheduler_type=\"cosine\",             # use cosine learning rate scheduler\n",
    "    logging_steps=25,                       # log every 25 steps\n",
    "    save_steps=500,                         # when to save checkpoint\n",
    "    save_total_limit=2,                     # limit the total amount of checkpoints\n",
    "    evaluation_strategy=\"steps\",            # evaluate every 1000 steps\n",
    "    eval_steps=700,                         # when to evaluate\n",
    "    bf16=True,                              # use bfloat16 precision\n",
    "    tf32=True,                              # use tf32 precision\n",
    "    push_to_hub=False,                      # push model to hub\n",
    "    report_to=\"tensorboard\",                # report metrics to tensorboard\n",
    ")\n",
    " \n",
    "dpo_args = {\n",
    "    \"beta\": 0.1,                            # The beta factor in DPO loss. Higher beta means less divergence\n",
    "    \"loss_type\": \"sigmoid\"                  # The loss type for DPO.\n",
    "}\n",
    "\n",
    "prompt_length = 402#1024\n",
    "max_seq_length = 912#1512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toskov/project-code-2024/venv/lib/python3.10/site-packages/trl/trainer/dpo_trainer.py:332: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<trl.trainer.dpo_trainer.DPOTrainer at 0x7f942a6d3130>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trl import DPOTrainer\n",
    "from datasets import Dataset\n",
    "\n",
    "policy_model.dpo_trainer = trainer_for_eval = DPOTrainer(\n",
    "    policy_model.pretrained_model,\n",
    "    ref_model=None, # set to none since we use peft\n",
    "    # peft_config=peft_config,\n",
    "    args=args,\n",
    "    train_dataset=Dataset.from_dict({}),\n",
    "    eval_dataset=Dataset.from_dict({}),\n",
    "    tokenizer=evaluator.policy_tokenizer,\n",
    "    max_length=max_seq_length,\n",
    "    max_prompt_length=prompt_length,\n",
    "    beta=dpo_args[\"beta\"],\n",
    "    loss_type=dpo_args[\"loss_type\"],\n",
    ")\n",
    "\n",
    "policy_model.dpo_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
